{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac13265a-3f9a-4c6d-abcf-9ff1b78a5fdb",
   "metadata": {},
   "source": [
    "**PIPELINE:**\n",
    "\n",
    "In this notebook:\n",
    "1. Raw video -> labelled keypoints (YOLO)\n",
    "2. Labelled keypoints video -> directory of images (split into frames)\n",
    "3. populate labelling table with start/end frames of k=10-frame sequences with l=5 overlap, split by target person\n",
    "\n",
    "Not in this notebook:\n",
    "    4. [Manual labelling]\n",
    "    5. feature generation\n",
    "    6. punch classification model (RNN/LSTM)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183e72b4-4abc-4c88-8cac-f37ed9076ca9",
   "metadata": {},
   "source": [
    "keypoints format:\n",
    "\n",
    "video id | sequence number | internal frame number(0 at seqstart) | target person | keypoints (as list)\n",
    "\n",
    "-> order keypoints by the left-to-right order of their appearance in the first frame of the sequence\n",
    "\n",
    "-> target person numbering resets per sequence\n",
    "\n",
    "labelling format (punch):\n",
    "\n",
    "video id | sequence number | start frame | end frame (=start+k) | target person | punch type (0-3) | include? (0-1)\n",
    "\n",
    "-> 0 = no punch; 1 = straight; 2 = hook; 3 = uppercut\n",
    "\n",
    "\n",
    "\n",
    "training data format:\n",
    "\n",
    "from labelling table, take rows with include==1 and access their keypoints by video id, start frame and target person\n",
    "\n",
    "video id | sequence number | start frame | end frame | target person | punch type | keypoints (as list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24a4eae-c970-4675-864c-75e87ada8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c78b512-8422-42fa-9f61-836c800d275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_PER_SEQUENCE = 10\n",
    "OVERLAP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4af12a7-9a8a-4e6f-8ca5-361473051056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Extract keypoints from video\n",
    "def extractKeypoints(video_fp,outputsDirectory,model):\n",
    "    \"\"\"\n",
    "    Extract and return keypoints tensor from video_fp using YOLOv8l 2D pose estimation model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = YOLO(f\"{model}-pose.pt\")\n",
    "    results = model(video_fp, project=output_dir, name=output_name, stream=False, save=True,max_det=5, save_conf=True, vid_stride=2, conf=0.4)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "befbafe7-4776-44c1-9bc1-7343398e6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: split labelled keypoints video into a folder of individual frames at dir frames_fp\n",
    "def splitVideoToFrames(labelledvideo_fp,frames_fp):\n",
    "    \"\"\"\n",
    "    Split video of labelled keypoints at labelledvideo_fp into individual frames\n",
    "    Save in directory frames_fp as jpg files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(frames_fp): os.makedirs(frames_fp)\n",
    "    video = cv2.VideoCapture(labelledvideo_fp)\n",
    "    if not video.isOpened():\n",
    "        print(f\"Error opening video {labelledvideo_fp}\")\n",
    "    i = 1\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret: break\n",
    "        frame_filename = os.path.join(frames_fp, f\"frame_{i:04d}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        i += 1\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0837abe0-5c66-47db-b670-b07e4dc7f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Assign person IDs to each character by sequence\n",
    "\n",
    "def assignIDNumbers(framesDir):\n",
    "    \"\"\"\n",
    "    Assign person IDs to each character in each sequence\n",
    "    Ordering: \n",
    "    \n",
    "    Return value: dictionary of [1-indexed sequence number]-> dictionary of \n",
    "    [1-indexed character number]->[index in keypoints for each frame in sequence]\n",
    "    \n",
    "    Assignment order:\n",
    "     - Left-to-right in first frame of sequence\n",
    "     - If a person doesn't appear in the first frame of a sequence don't classify him.\n",
    "     - One-indexed\n",
    "    \"\"\"\n",
    "    \n",
    "    def modified_cossim(v1,v2):\n",
    "        \"\"\"\n",
    "        Helper function\n",
    "        Modified cosine similarity: only nonzero elements are considered \n",
    "        \"\"\"\n",
    "        v1p = np.where((v1 != 0) & (v2 != 0), v1, 0)\n",
    "        v2p = np.where((v1 != 0) & (v2 != 0), v2, 0)\n",
    "        if np.sum(v1p)==0 or np.sum(v2p)==0:\n",
    "            return 0\n",
    "        return (v1p @ v2p)/(np.linalg.norm(v1p)*np.linalg.norm(v2p))\n",
    "        \n",
    "    def sortfn(x):\n",
    "        \"\"\"\n",
    "        Helper function\n",
    "        We will order people left-to-right by the minimum x coordinate of their nonzero \n",
    "        keypoints in the first frame of the sequence\n",
    "        \"\"\"\n",
    "        arr = np.array(sequence[0].keypoints.xy[x-1].tolist())[:,0]\n",
    "        if len(arr[arr>0])>0:\n",
    "            return arr[arr > 0].min()\n",
    "        return 0\n",
    "\n",
    "    def findCameraChanges(framesDir, threshold=0.8):\n",
    "        \"\"\"\n",
    "        Helper function\n",
    "        Detect camera angle changes in a directory of frames. Return a list of zero-indexed frame numbers of such changes        \n",
    "        \"\"\"\n",
    "        angle_change_frames = []\n",
    "        prev_hist = None\n",
    "    \n",
    "        files = sorted(os.listdir(framesDir))\n",
    "        \n",
    "        for i,file in enumerate(files):\n",
    "            if not file.endswith('.jpg'): continue  # Skip non-JPG files\n",
    "            \n",
    "            frame_path = os.path.join(framesDir, file)\n",
    "            frame = cv2.imread(frame_path)\n",
    "    \n",
    "            if frame is None: \n",
    "                print(f'Found unreadable frame: {i}')\n",
    "                continue #skip unreadable frames\n",
    "            \n",
    "            curr_hist = cv2.calcHist([frame], [0], None, [256], [0, 256])\n",
    "            \n",
    "            if prev_hist is not None:\n",
    "                # Compare curr frame's histogram with prev frame's histogram\n",
    "                similarity = cv2.compareHist(prev_hist, curr_hist, cv2.HISTCMP_CORREL)\n",
    "                \n",
    "                if similarity < threshold:\n",
    "                    angle_change_frames.append(int(file[-8:-4])-1)\n",
    "            \n",
    "            prev_hist = curr_hist\n",
    "    \n",
    "        return angle_change_frames\n",
    "    \n",
    "    ID_assignments = dict()\n",
    "    num_frames = len(results)\n",
    "\n",
    "    angleChangeFrames = findCameraChanges(framesDir)    \n",
    "    for s in range(0,num_frames,OVERLAP):\n",
    "        print(f\"Processing sequence {int(s/OVERLAP) + 1}\")\n",
    "        sequence = results[s:s+FRAMES_PER_SEQUENCE]\n",
    "        if len(sequence) != FRAMES_PER_SEQUENCE: break #means we're done processing\n",
    "\n",
    "        #ensure that the sequence doesn't contain any frames with camera angle changes\n",
    "        skip = False\n",
    "        for i in range(s,s+FRAMES_PER_SEQUENCE):\n",
    "            if i in angleChangeFrames:\n",
    "                skip = True\n",
    "                break\n",
    "        if skip: continue\n",
    "\n",
    "        #ensure that the sequence doesn't contain any frames without ID'd characters\n",
    "        skip = False\n",
    "        for i in range(FRAMES_PER_SEQUENCE):\n",
    "            if len(sequence[i].keypoints.xy[0])==0:\n",
    "                skip = True     \n",
    "                break\n",
    "        if skip: continue\n",
    "    \n",
    "        #characters dictionary\n",
    "        #character with key i will contain a list which is his tensor array indexes for each frame\n",
    "        characters = dict() \n",
    "    \n",
    "        #name pts left to rights from first frame in seq\n",
    "        order = sorted([r+1 for r in range(len(sequence[0].keypoints.xy))], key =sortfn) \n",
    "        for r in range(len(sequence[0].keypoints.xy)): characters[order[r]] = [r]\n",
    "    \n",
    "        sims = [] #keep track of avg similarity at each new layer\n",
    "        bestsim = 0\n",
    "        \n",
    "        #match indexes at curr \"layer\" to those from prev layer \"layer-1\"\n",
    "        for layer in range(1,FRAMES_PER_SEQUENCE):                \n",
    "            \n",
    "            indexes = [r for r in range(len(sequence[layer].keypoints.xy))]\n",
    "            seq_num = int(s/OVERLAP) + 1\n",
    "                \n",
    "            #match every character in \"layer\" one at a time\n",
    "            for key in characters.keys():\n",
    "                #if character doesnt exist in prev layer then skip it\n",
    "                if characters[key][-1] >= len(sequence[layer-1].keypoints.xy): continue\n",
    "    \n",
    "                #vector of character[key] in prev layer\n",
    "                v1 = np.array(sequence[layer-1].keypoints.xy[characters[key][-1]].tolist()).flatten()\n",
    "                bestindex = -1; maxsim = 0\n",
    "    \n",
    "                #if we've used up all of the indexes just break\n",
    "                if not indexes:\n",
    "                    characters[key].append(-1)\n",
    "                    continue\n",
    "    \n",
    "                #figure out the best index to match to character[key] in layer\n",
    "                for index in indexes:\n",
    "                    v2 = np.array(sequence[layer].keypoints.xy[index].tolist()).flatten()\n",
    "                    sim = modified_cossim(v1,v2)\n",
    "                    if sim >= maxsim:\n",
    "                        maxsim = sim\n",
    "                        bestindex = index\n",
    "                \n",
    "                characters[key].append(bestindex)\n",
    "                if bestindex != -1: indexes.remove(bestindex)\n",
    "    \n",
    "        ID_assignments[int(s/OVERLAP)+1] = characters #key: 1-indexed seq number, value: character assignments dict\n",
    "    return ID_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d49357c-25aa-4c79-a3c5-79d7c52c1012",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS FOR USE:**\n",
    "\n",
    "To run the preprocessing script, you need:\n",
    " - raw videos in file folder \"raw\", mp4 file format\n",
    " - created output directory \"labelled\"\n",
    "Note that file paths are all relative, so keep this notebook in the same directory that contains directories \"raw\" and \"labelled\"\n",
    "\n",
    "Additionally, the following libraries must be installed on your system: ultralytics, numpy, opencv-python (cv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b60040d-5eda-4e5b-8214-5e2a46705703",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawvideos_dir = \"raw\"\n",
    "video_fp = \"raw/short10.mp4\" #video path\n",
    "output_dir = \"labelled\" #make sure it actually exists\n",
    "model = \"yolov8l\"\n",
    "\n",
    "output_name = f\"{video_fp[len(rawvideos_dir)+1:][:-4]}\"\n",
    "\n",
    "labelledvideo_fp = f\"{output_dir}/{output_name}/{video_fp[len(rawvideos_dir)+1:]}\"\n",
    "frames_fp = f\"{output_dir}/{output_name}/frames\"\n",
    "keypoints_fp = f\"{output_dir}/{output_name}/keypoints.csv\"\n",
    "table_fp = f\"{output_dir}/{output_name}/table.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e86c5a5-301f-420a-9afd-fcd689d5d9ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8l-pose.pt to 'yolov8l-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85.3M/85.3M [00:13<00:00, 6.48MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video 1/1 (1/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 3165.3ms\n",
      "video 1/1 (2/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 2110.5ms\n",
      "video 1/1 (3/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1876.4ms\n",
      "video 1/1 (4/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1705.6ms\n",
      "video 1/1 (5/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1686.1ms\n",
      "video 1/1 (6/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1675.8ms\n",
      "video 1/1 (7/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1672.4ms\n",
      "video 1/1 (8/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1815.2ms\n",
      "video 1/1 (9/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2024.5ms\n",
      "video 1/1 (10/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1827.5ms\n",
      "video 1/1 (11/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1676.7ms\n",
      "video 1/1 (12/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1683.4ms\n",
      "video 1/1 (13/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1649.9ms\n",
      "video 1/1 (14/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1763.8ms\n",
      "video 1/1 (15/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1674.6ms\n",
      "video 1/1 (16/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1664.9ms\n",
      "video 1/1 (17/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1857.6ms\n",
      "video 1/1 (18/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2043.3ms\n",
      "video 1/1 (19/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1904.0ms\n",
      "video 1/1 (20/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1716.3ms\n",
      "video 1/1 (21/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1676.2ms\n",
      "video 1/1 (22/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1668.7ms\n",
      "video 1/1 (23/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1698.2ms\n",
      "video 1/1 (24/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1737.1ms\n",
      "video 1/1 (25/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1829.5ms\n",
      "video 1/1 (26/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2246.5ms\n",
      "video 1/1 (27/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2114.4ms\n",
      "video 1/1 (28/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1876.5ms\n",
      "video 1/1 (29/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1736.4ms\n",
      "video 1/1 (30/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1787.9ms\n",
      "video 1/1 (31/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1749.2ms\n",
      "video 1/1 (32/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1730.9ms\n",
      "video 1/1 (33/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1748.2ms\n",
      "video 1/1 (34/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1829.8ms\n",
      "video 1/1 (35/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2057.9ms\n",
      "video 1/1 (36/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1807.4ms\n",
      "video 1/1 (37/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1670.6ms\n",
      "video 1/1 (38/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1678.3ms\n",
      "video 1/1 (39/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1683.7ms\n",
      "video 1/1 (40/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1719.4ms\n",
      "video 1/1 (41/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1693.8ms\n",
      "video 1/1 (42/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1920.3ms\n",
      "video 1/1 (43/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2246.1ms\n",
      "video 1/1 (44/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2076.7ms\n",
      "video 1/1 (45/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1717.7ms\n",
      "video 1/1 (46/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1679.1ms\n",
      "video 1/1 (47/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1724.6ms\n",
      "video 1/1 (48/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1750.9ms\n",
      "video 1/1 (49/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1739.2ms\n",
      "video 1/1 (50/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1727.0ms\n",
      "video 1/1 (51/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1866.3ms\n",
      "video 1/1 (52/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2402.8ms\n",
      "video 1/1 (53/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1947.9ms\n",
      "video 1/1 (54/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1808.0ms\n",
      "video 1/1 (55/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1845.9ms\n",
      "video 1/1 (56/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1822.0ms\n",
      "video 1/1 (57/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1859.4ms\n",
      "video 1/1 (58/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1805.8ms\n",
      "video 1/1 (59/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1811.7ms\n",
      "video 1/1 (60/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2118.4ms\n",
      "video 1/1 (61/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2022.6ms\n",
      "video 1/1 (62/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1782.1ms\n",
      "video 1/1 (63/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1779.7ms\n",
      "video 1/1 (64/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1991.3ms\n",
      "video 1/1 (65/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1996.2ms\n",
      "video 1/1 (66/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2301.5ms\n",
      "video 1/1 (67/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2765.2ms\n",
      "video 1/1 (68/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2547.1ms\n",
      "video 1/1 (69/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2266.6ms\n",
      "video 1/1 (70/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2229.8ms\n",
      "video 1/1 (71/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2366.8ms\n",
      "video 1/1 (72/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2173.1ms\n",
      "video 1/1 (73/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2139.5ms\n",
      "video 1/1 (74/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2298.6ms\n",
      "video 1/1 (75/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2437.3ms\n",
      "video 1/1 (76/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1778.0ms\n",
      "video 1/1 (77/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1759.7ms\n",
      "video 1/1 (78/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1798.1ms\n",
      "video 1/1 (79/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1794.7ms\n",
      "video 1/1 (80/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2010.1ms\n",
      "video 1/1 (81/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1761.5ms\n",
      "video 1/1 (82/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2211.0ms\n",
      "video 1/1 (83/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2170.8ms\n",
      "video 1/1 (84/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1870.8ms\n",
      "video 1/1 (85/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1804.7ms\n",
      "video 1/1 (86/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1846.6ms\n",
      "video 1/1 (87/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1805.2ms\n",
      "video 1/1 (88/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1795.2ms\n",
      "video 1/1 (89/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2052.4ms\n",
      "video 1/1 (90/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2168.4ms\n",
      "video 1/1 (91/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2138.6ms\n",
      "video 1/1 (92/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1809.0ms\n",
      "video 1/1 (93/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1814.3ms\n",
      "video 1/1 (94/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 1827.3ms\n",
      "video 1/1 (95/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1826.7ms\n",
      "video 1/1 (96/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1984.6ms\n",
      "video 1/1 (97/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2039.9ms\n",
      "video 1/1 (98/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2108.8ms\n",
      "video 1/1 (99/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 2110.0ms\n",
      "video 1/1 (100/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1777.6ms\n",
      "video 1/1 (101/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1737.9ms\n",
      "video 1/1 (102/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1770.5ms\n",
      "video 1/1 (103/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1972.9ms\n",
      "video 1/1 (104/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1800.6ms\n",
      "video 1/1 (105/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1814.4ms\n",
      "video 1/1 (106/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1902.5ms\n",
      "video 1/1 (107/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 4 persons, 2125.7ms\n",
      "video 1/1 (108/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 5 persons, 1883.0ms\n",
      "video 1/1 (109/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1829.8ms\n",
      "video 1/1 (110/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 1 person, 2501.5ms\n",
      "video 1/1 (111/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1908.3ms\n",
      "video 1/1 (112/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 1 person, 1860.4ms\n",
      "video 1/1 (113/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 1 person, 1835.3ms\n",
      "video 1/1 (114/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 1 person, 1981.9ms\n",
      "video 1/1 (115/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 1 person, 2290.5ms\n",
      "video 1/1 (116/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1906.3ms\n",
      "video 1/1 (117/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1788.1ms\n",
      "video 1/1 (118/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1833.9ms\n",
      "video 1/1 (119/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1990.0ms\n",
      "video 1/1 (120/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 3 persons, 1950.8ms\n",
      "video 1/1 (121/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1752.3ms\n",
      "video 1/1 (122/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1906.2ms\n",
      "video 1/1 (123/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 2077.2ms\n",
      "video 1/1 (124/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1960.2ms\n",
      "video 1/1 (125/125) /Users/yuchenli/Documents/CS229/raw/short10.mp4: 384x640 2 persons, 1769.6ms\n",
      "Speed: 3.3ms preprocess, 1920.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mlabelled/short10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = extractKeypoints(video_fp,output_dir,model)\n",
    "splitVideoToFrames(labelledvideo_fp,frames_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fe7f31d1-d879-41e1-8be0-561d68402adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence 1\n",
      "Processing sequence 2\n",
      "Processing sequence 3\n",
      "Processing sequence 4\n",
      "Processing sequence 5\n",
      "Processing sequence 6\n",
      "Processing sequence 7\n",
      "Processing sequence 8\n",
      "Processing sequence 9\n",
      "Processing sequence 10\n",
      "Processing sequence 11\n",
      "Processing sequence 12\n",
      "Processing sequence 13\n",
      "Processing sequence 14\n",
      "Processing sequence 15\n",
      "Processing sequence 16\n",
      "Processing sequence 17\n",
      "Processing sequence 18\n",
      "Processing sequence 19\n",
      "Processing sequence 20\n",
      "Processing sequence 21\n",
      "Processing sequence 22\n",
      "Processing sequence 23\n",
      "Processing sequence 24\n",
      "Processing sequence 25\n"
     ]
    }
   ],
   "source": [
    "IDs = assignIDNumbers(frames_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99e804c-cd36-4bf3-ba6a-81569efd1fb4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 1, 1, 1, 1, 2, 1, 1, 1, 1],\n",
       "  2: [2, 2, 2, 2, 2, 1, 2, 2, 2, 2],\n",
       "  4: [3, -1, -1, 3, 4, 3, 4, 3, 3, -1]},\n",
       " 2: {2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  3: [2, 1, 1, 1, 1, 1, 1, 1, 1, 4],\n",
       "  4: [3, 4, 3, 3, -1, -1, 3, 3, 3, 1]},\n",
       " 3: {3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 1, 1, 1, 4, 3, 4, 1, 1, 1],\n",
       "  2: [2, 2, 2, 2, 2, 2, 2, 2, 2, 3]},\n",
       " 4: {3: [0, 0, 0, 0, 0, 2, 2, 2, 3, 0],\n",
       "  1: [1, 4, 1, 1, 1, 0, 1, 0, 2, 1],\n",
       "  4: [2, 2, 2, 2, 3, 1, 0, 1, 0, 2],\n",
       "  2: [3, 3, 3, 3, 4, -1, 4, 4, 1, -1],\n",
       "  5: [4, 1, -1, -1, 2, 3, 3, 4]},\n",
       " 5: {3: [0, 1, 0, 2, 1, 2, 2, 2, 2, 1],\n",
       "  2: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [2, 2, 2, 3, 2, 1, 1, 1, 1, 2]},\n",
       " 6: {2: [0, 2, 2, 2, 1, 0, 1, 1, 1, 0],\n",
       "  1: [1, 1, 1, 1, 2, 2, 2, 2, 3, 1],\n",
       "  3: [2, 0, 0, 0, 0, 1, 0, 0, 0, 3],\n",
       "  4: [3, 4, 3, 4, 3, 3, 3, 3, 4, 2],\n",
       "  5: [4, 3, 4, 3, -1, 4, -1, 4, 2, -1]},\n",
       " 7: {4: [0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
       "  3: [1, 0, 0, 0, 1, 1, 1, 0, 1, 1],\n",
       "  2: [2, 2, 2, 3, 3, 3, 2, 2, 2, 3],\n",
       "  5: [3, 3, 3, 4, 2, 2, -1, -1, -1, 4],\n",
       "  1: [4, -1, 4, 2, -1, -1, 2]},\n",
       " 8: {3: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1],\n",
       "  4: [1, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
       "  2: [2, 2, 2, 2, 3, 3, 3, 4, 3, 3],\n",
       "  1: [3, -1, -1, -1, 4, 4, 4, 3, 2, 2]},\n",
       " 9: {4: [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  5: [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  2: [2, 2, 2, 4, 2, 2, 2, 2, 4, 2],\n",
       "  3: [3, 3, 4, 3, 3, 4, -1, 3, 3, 4],\n",
       "  1: [4, 4, 3, 2, -1, 3, 2, 3]},\n",
       " 10: {5: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  3: [1, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
       "  1: [2, 2, 2, 4, 2, 4, 4, 4, 3, 0],\n",
       "  4: [3, -1, 3, 3, 4, 2, 3, 2, 2, 2],\n",
       "  2: [4, 3, 3, 2, 3, 4, 4]},\n",
       " 11: {4: [0, 0, 0, 0, 1, 2, 2, 2, 2, 2],\n",
       "  3: [1, 1, 1, 1, 3, 4, 0, 0, 1, 1],\n",
       "  1: [2, 3, 2, 2, 2, 3, 3, 3, 3, 0],\n",
       "  5: [3, 2, 3, 3, 0, 0, 1, 1, 0, 4],\n",
       "  2: [4, 4, 4, 4, 4, 1, -1, -1, 4, 3]},\n",
       " 12: {2: [0, 0, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "  4: [1, 1, 1, 0, 0, 1, 0, 1, 1, 0],\n",
       "  1: [2, 2, 2, 2, 2, 3, 2, 3, 4, 2],\n",
       "  3: [3, 3, 3, 3, 4, 2, 4, 2, 3, 3],\n",
       "  5: [4, -1, -1, 4, 3, -1, 3, -1, 2, 4]},\n",
       " 13: {3: [0, 1, 0, 0, 1, 0, 2, 3, 0, 1],\n",
       "  2: [1, 0, 1, 1, 0, 1, 3, 2, 1, 0],\n",
       "  1: [2, 4, 3, 4, 2, 3, 1, 0, 4, 4],\n",
       "  4: [3, 2, 2, 3, 3, 2, 4, 1, 2, 2]},\n",
       " 14: {3: [0, 2, 3, 0, 1, 1, 2, 3, 1, 4],\n",
       "  2: [1, 3, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "  4: [2, 4, 0, 4, 4, 4, 1, 1, 4, 3],\n",
       "  1: [3, 1, 1, 2, 2, 2, 3, 2, 3, 2]},\n",
       " 15: {4: [0, 0, 0, 0, 0, 3, 2, 4, 2, 0],\n",
       "  1: [1, 2, 3, 1, 4, 0, 0, 0, 0, 1],\n",
       "  5: [2, 1, 1, 4, 3, 4, 1, 1, 1, 2],\n",
       "  3: [3, 3, 2, 3, 2, 2, -1, 2, 3, 4],\n",
       "  2: [4, -1, -1, 2, 1, 1, 3, 4, 3]},\n",
       " 16: {3: [0, 0, 0, 0, 1, 0, 3, 3, 1, 1],\n",
       "  4: [1, 1, 1, 1, 2, 1, 4, 0, 0, 0],\n",
       "  1: [2, 2, 4, 2, 0, 2, 0, 4, 2, 2],\n",
       "  2: [3, -1, 2, 3, 4, 4, 1, 1, 4, 4],\n",
       "  5: [4, 4, 3, 3, 2, 2, 3, 3]},\n",
       " 17: {4: [0, 3, 3, 1, 1, 1, 1, 1, 1, 0],\n",
       "  3: [1, 4, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  5: [2, 0, 4, 2, 2, 4, 2, 2, 2, 2],\n",
       "  2: [3, 2, 1, 4, 4, 3, 4, 3, 4, 4],\n",
       "  1: [4, 1, 2, 3, 3, 2, 3, 4, 3, 3]},\n",
       " 20: {4: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "  2: [2, 2, 3, 3, 3, 2, 2, 2, 2, 3],\n",
       "  5: [3, 3, 2, 2, 4, 4, 4, -1, 3, 4],\n",
       "  3: [4, 4, 4, 4, 2, 3, 3, 2]},\n",
       " 21: {1: [0, 0, 0, 0, 1, 2, 3, 1, 1, 0],\n",
       "  2: [1, 1, 1, 1, 0, 1, 0, 0, 0, -1],\n",
       "  5: [2, 2, 2, 2, 3, 4, 1, 2, -1],\n",
       "  3: [3, 3, -1, 3, 4, 0, 2, 3],\n",
       "  4: [4, 4, 2, 3, -1, 4]},\n",
       " 22: {3: [0, 1, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "  2: [1, 0, 0, 0, -1, 1, -1, -1, -1, -1],\n",
       "  4: [2, 3, 1, -1, -1],\n",
       "  5: [3, 2, 3],\n",
       "  1: [4, -1, 4]},\n",
       " 23: {1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  2: [1, -1, -1, -1, -1, 2, 1, 2, 1, 2]},\n",
       " 24: {3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  2: [1, 1, 2, 1, 2, 1, 1, 1, 1, 1],\n",
       "  1: [2, -1, 1, -1, 1, -1, -1, -1, -1, -1]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f345440-23d4-4d3e-9021-89180e37bba4",
   "metadata": {},
   "source": [
    "# Write keypoints to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ffe586d-a96d-47c5-b0cf-ecd06e863a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#write keypoints data to csv\n",
    "#after this, another fn needs to populate the labelling table. \n",
    "lines = []\n",
    "import csv \n",
    "\n",
    "for sequence in IDs.keys():\n",
    "    seqstart = (sequence-1)*OVERLAP   \n",
    "    for internal_frame in range(FRAMES_PER_SEQUENCE):\n",
    "        external_frame = seqstart + internal_frame\n",
    "        for person in IDs[sequence].keys():\n",
    "            if len(IDs[sequence][person]) > internal_frame and IDs[sequence][person][internal_frame]!=-1:\n",
    "                index = IDs[sequence][person][internal_frame]\n",
    "                #print(index)\n",
    "                #print(results[external_frame].keypoints.xy)\n",
    "                keypoints = np.array(results[external_frame].keypoints.xy[index].tolist()).flatten().tolist()\n",
    "                line = [output_name, sequence, internal_frame, person] + keypoints\n",
    "                lines.append(line)\n",
    "                \n",
    "with open(keypoints_fp, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write all lines to the CSV file\n",
    "    writer.writerows(lines)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9d160c-30df-48fa-b506-c0c51d6190d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Debugging code for fixing a bug (now fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5de6053-92c4-4169-a3b1-299aa8d6fcf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 4, frame_start 21 found [4, 1, -1, -1, 2, 3, 3, 4]\n",
      "Sequence 7, frame_start 36 found [4, -1, 4, 2, -1, -1, 2]\n",
      "Sequence 9, frame_start 46 found [4, 4, 3, 2, -1, 3, 2, 3]\n",
      "Sequence 10, frame_start 51 found [4, 3, 3, 2, 3, 4, 4]\n",
      "Sequence 15, frame_start 76 found [4, -1, -1, 2, 1, 1, 3, 4, 3]\n",
      "Sequence 16, frame_start 81 found [4, 4, 3, 3, 2, 2, 3, 3]\n",
      "Sequence 20, frame_start 101 found [4, 4, 4, 4, 2, 3, 3, 2]\n",
      "Sequence 21, frame_start 106 found [2, 2, 2, 2, 3, 4, 1, 2, -1]\n",
      "Sequence 21, frame_start 106 found [3, 3, -1, 3, 4, 0, 2, 3]\n",
      "Sequence 21, frame_start 106 found [4, 4, 2, 3, -1, 4]\n",
      "Sequence 22, frame_start 111 found [2, 3, 1, -1, -1]\n",
      "Sequence 22, frame_start 111 found [3, 2, 3]\n",
      "Sequence 22, frame_start 111 found [4, -1, 4]\n"
     ]
    }
   ],
   "source": [
    "for i in IDs.keys():\n",
    "    for j,pos_index in enumerate(IDs[i].values()):\n",
    "        if not len(pos_index) == 10:\n",
    "            frame_start = i * OVERLAP + 1\n",
    "            print(f'Sequence {i}, frame_start {frame_start} found {pos_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6ddc551-5a61-4b58-a40f-57fd78753516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93]\n",
      "Processing sequence 1\n",
      "Processing sequence 2\n",
      "Processing sequence 3\n",
      "Processing sequence 4\n",
      "Processing sequence 5\n",
      "Processing sequence 6\n",
      "Processing sequence 7\n",
      "Processing sequence 8\n",
      "Processing sequence 9\n",
      "Processing sequence 10\n",
      "Processing sequence 11\n",
      "Processing sequence 12\n",
      "Processing sequence 13\n",
      "Processing sequence 14\n",
      "Processing sequence 15\n",
      "Processing sequence 16\n",
      "Processing sequence 17\n",
      "Processing sequence 18\n",
      "Processing sequence 19\n",
      "Processing sequence 20\n",
      "Processing sequence 21\n",
      "Processing sequence 22\n",
      "Local frame 1. Indexes = [0, 1, 2, 3] \n",
      "Characters = {3: [0], 2: [1], 4: [2], 5: [3], 1: [4]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "For 3, best positional index based on cossim is 1\n",
      "Checking character 2\n",
      "For 2, best positional index based on cossim is 0\n",
      "Checking character 4\n",
      "For 4, best positional index based on cossim is 2\n",
      "For 4, best positional index based on cossim is 3\n",
      "Checking character 5\n",
      "For 5, best positional index based on cossim is 2\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 2. Indexes = [0, 1, 2, 3, 4] \n",
      "Characters = {3: [0, 1], 2: [1, 0], 4: [2, 3], 5: [3, 2], 1: [4, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "For 3, best positional index based on cossim is 2\n",
      "Checking character 2\n",
      "For 2, best positional index based on cossim is 0\n",
      "Checking character 4\n",
      "For 4, best positional index based on cossim is 1\n",
      "Checking character 5\n",
      "For 5, best positional index based on cossim is 3\n",
      "Checking character 1\n",
      "For 1, best positional index based on cossim is 4\n",
      "Local frame 3. Indexes = [0, 1] \n",
      "Characters = {3: [0, 1, 2], 2: [1, 0, 0], 4: [2, 3, 1], 5: [3, 2, 3], 1: [4, -1, 4]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "For 3, best positional index based on cossim is 1\n",
      "Checking character 2\n",
      "For 2, best positional index based on cossim is 0\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 4. Indexes = [0] \n",
      "Characters = {3: [0, 1, 2, 1], 2: [1, 0, 0, 0], 4: [2, 3, 1, -1], 5: [3, 2, 3, -1], 1: [4, -1, 4, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "Checking character 2\n",
      "Found no indexes, appending -1\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 5. Indexes = [0, 1] \n",
      "Characters = {3: [0, 1, 2, 1, 0], 2: [1, 0, 0, 0, -1], 4: [2, 3, 1, -1, -1], 5: [3, 2, 3, -1, -1], 1: [4, -1, 4, -1, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "Checking character 2\n",
      "For 2, best positional index based on cossim is 1\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 6. Indexes = [0] \n",
      "Characters = {3: [0, 1, 2, 1, 0, 0], 2: [1, 0, 0, 0, -1, 1], 4: [2, 3, 1, -1, -1, -1], 5: [3, 2, 3, -1, -1, -1], 1: [4, -1, 4, -1, -1, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "Checking character 2\n",
      "Found no indexes, appending -1\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 7. Indexes = [0] \n",
      "Characters = {3: [0, 1, 2, 1, 0, 0, 0], 2: [1, 0, 0, 0, -1, 1, -1], 4: [2, 3, 1, -1, -1, -1, -1], 5: [3, 2, 3, -1, -1, -1, -1], 1: [4, -1, 4, -1, -1, -1, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "Checking character 2\n",
      "Found no indexes, appending -1\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 8. Indexes = [0] \n",
      "Characters = {3: [0, 1, 2, 1, 0, 0, 0, 0], 2: [1, 0, 0, 0, -1, 1, -1, -1], 4: [2, 3, 1, -1, -1, -1, -1, -1], 5: [3, 2, 3, -1, -1, -1, -1, -1], 1: [4, -1, 4, -1, -1, -1, -1, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "Checking character 2\n",
      "Found no indexes, appending -1\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Local frame 9. Indexes = [0] \n",
      "Characters = {3: [0, 1, 2, 1, 0, 0, 0, 0, 0], 2: [1, 0, 0, 0, -1, 1, -1, -1, -1], 4: [2, 3, 1, -1, -1, -1, -1, -1, -1], 5: [3, 2, 3, -1, -1, -1, -1, -1, -1], 1: [4, -1, 4, -1, -1, -1, -1, -1, -1]}\n",
      "Checking character 3\n",
      "For 3, best positional index based on cossim is 0\n",
      "Checking character 2\n",
      "Found no indexes, appending -1\n",
      "Checking character 4\n",
      "Found no indexes, appending -1\n",
      "Checking character 5\n",
      "Found no indexes, appending -1\n",
      "Checking character 1\n",
      "Found no indexes, appending -1\n",
      "Processing sequence 23\n",
      "Processing sequence 24\n",
      "Processing sequence 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: {3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 1, 1, 1, 1, 2, 1, 1, 1, 1],\n",
       "  2: [2, 2, 2, 2, 2, 1, 2, 2, 2, 2],\n",
       "  4: [3, -1, -1, 3, 4, 3, 4, 3, 3, -1]},\n",
       " 2: {2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "  3: [2, 1, 1, 1, 1, 1, 1, 1, 1, 4],\n",
       "  4: [3, 4, 3, 3, -1, -1, 3, 3, 3, 1]},\n",
       " 3: {3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [1, 1, 1, 1, 4, 3, 4, 1, 1, 1],\n",
       "  2: [2, 2, 2, 2, 2, 2, 2, 2, 2, 3]},\n",
       " 4: {3: [0, 0, 0, 0, 0, 2, 2, 2, 3, 0],\n",
       "  1: [1, 4, 1, 1, 1, 0, 1, 0, 2, 1],\n",
       "  4: [2, 2, 2, 2, 3, 1, 0, 1, 0, 2],\n",
       "  2: [3, 3, 3, 3, 4, -1, 4, 4, 1, -1],\n",
       "  5: [4, 1, -1, -1, 2, -1, 3, 3, 4, -1]},\n",
       " 5: {3: [0, 1, 0, 2, 1, 2, 2, 2, 2, 1],\n",
       "  2: [1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [2, 2, 2, 3, 2, 1, 1, 1, 1, 2]},\n",
       " 6: {2: [0, 2, 2, 2, 1, 0, 1, 1, 1, 0],\n",
       "  1: [1, 1, 1, 1, 2, 2, 2, 2, 3, 1],\n",
       "  3: [2, 0, 0, 0, 0, 1, 0, 0, 0, 3],\n",
       "  4: [3, 4, 3, 4, 3, 3, 3, 3, 4, 2],\n",
       "  5: [4, 3, 4, 3, -1, 4, -1, 4, 2, -1]},\n",
       " 7: {4: [0, 1, 1, 1, 0, 0, 0, 1, 0, 0],\n",
       "  3: [1, 0, 0, 0, 1, 1, 1, 0, 1, 1],\n",
       "  2: [2, 2, 2, 3, 3, 3, 2, 2, 2, 3],\n",
       "  5: [3, 3, 3, 4, 2, 2, -1, -1, -1, 4],\n",
       "  1: [4, -1, 4, 2, -1, -1, -1, -1, -1, 2]},\n",
       " 8: {3: [0, 0, 1, 0, 0, 0, 0, 1, 1, 1],\n",
       "  4: [1, 1, 0, 1, 1, 1, 1, 0, 0, 0],\n",
       "  2: [2, 2, 2, 2, 3, 3, 3, 4, 3, 3],\n",
       "  1: [3, -1, -1, -1, 4, 4, 4, 3, 2, 2]},\n",
       " 9: {4: [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  5: [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  2: [2, 2, 2, 4, 2, 2, 2, 2, 4, 2],\n",
       "  3: [3, 3, 4, 3, 3, 4, -1, 3, 3, 4],\n",
       "  1: [4, 4, 3, 2, -1, 3, -1, -1, 2, 3]},\n",
       " 10: {5: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  3: [1, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n",
       "  1: [2, 2, 2, 4, 2, 4, 4, 4, 3, 0],\n",
       "  4: [3, -1, 3, 3, 4, 2, 3, 2, 2, 2],\n",
       "  2: [4, -1, -1, 2, 3, 3, 2, 3, 4, 4]},\n",
       " 11: {4: [0, 0, 0, 0, 1, 2, 2, 2, 2, 2],\n",
       "  3: [1, 1, 1, 1, 3, 4, 0, 0, 1, 1],\n",
       "  1: [2, 3, 2, 2, 2, 3, 3, 3, 3, 0],\n",
       "  5: [3, 2, 3, 3, 0, 0, 1, 1, 0, 4],\n",
       "  2: [4, 4, 4, 4, 4, 1, -1, -1, 4, 3]},\n",
       " 12: {2: [0, 0, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "  4: [1, 1, 1, 0, 0, 1, 0, 1, 1, 0],\n",
       "  1: [2, 2, 2, 2, 2, 3, 2, 3, 4, 2],\n",
       "  3: [3, 3, 3, 3, 4, 2, 4, 2, 3, 3],\n",
       "  5: [4, -1, -1, 4, 3, -1, 3, -1, 2, 4]},\n",
       " 13: {3: [0, 1, 0, 0, 1, 0, 2, 3, 0, 1],\n",
       "  2: [1, 0, 1, 1, 0, 1, 3, 2, 1, 0],\n",
       "  1: [2, 4, 3, 4, 2, 3, 1, 0, 4, 4],\n",
       "  4: [3, 2, 2, 3, 3, 2, 4, 1, 2, 2]},\n",
       " 14: {3: [0, 2, 3, 0, 1, 1, 2, 3, 1, 4],\n",
       "  2: [1, 3, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "  4: [2, 4, 0, 4, 4, 4, 1, 1, 4, 3],\n",
       "  1: [3, 1, 1, 2, 2, 2, 3, 2, 3, 2]},\n",
       " 15: {4: [0, 0, 0, 0, 0, 3, 2, 4, 2, 0],\n",
       "  1: [1, 2, 3, 1, 4, 0, 0, 0, 0, 1],\n",
       "  5: [2, 1, 1, 4, 3, 4, 1, 1, 1, 2],\n",
       "  3: [3, 3, 2, 3, 2, 2, -1, 2, 3, 4],\n",
       "  2: [4, -1, -1, 2, 1, 1, -1, 3, 4, 3]},\n",
       " 16: {3: [0, 0, 0, 0, 1, 0, 3, 3, 1, 1],\n",
       "  4: [1, 1, 1, 1, 2, 1, 4, 0, 0, 0],\n",
       "  1: [2, 2, 4, 2, 0, 2, 0, 4, 2, 2],\n",
       "  2: [3, -1, 2, 3, 4, 4, 1, 1, 4, 4],\n",
       "  5: [4, -1, 3, 4, 3, 3, 2, 2, 3, 3]},\n",
       " 17: {4: [0, 3, 3, 1, 1, 1, 1, 1, 1, 0],\n",
       "  3: [1, 4, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  5: [2, 0, 4, 2, 2, 4, 2, 2, 2, 2],\n",
       "  2: [3, 2, 1, 4, 4, 3, 4, 3, 4, 4],\n",
       "  1: [4, 1, 2, 3, 3, 2, 3, 4, 3, 3]},\n",
       " 20: {4: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  1: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "  2: [2, 2, 3, 3, 3, 2, 2, 2, 2, 3],\n",
       "  5: [3, 3, 2, 2, 4, 4, 4, -1, 3, 4],\n",
       "  3: [4, 4, 4, 4, 2, 3, 3, -1, 4, 2]},\n",
       " 21: {1: [0, 0, 0, 0, 1, 2, 3, 1, 1, 0],\n",
       "  2: [1, 1, 1, 1, 0, 1, 0, 0, 0, -1],\n",
       "  5: [2, 2, 2, 2, 3, 4, 1, 2, -1, -1],\n",
       "  3: [3, 3, -1, 3, 4, 0, 2, 3, -1, -1],\n",
       "  4: [4, 4, -1, 4, 2, 3, -1, 4, -1, -1]},\n",
       " 22: {3: [0, 1, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       "  2: [1, 0, 0, 0, -1, 1, -1, -1, -1, -1],\n",
       "  4: [2, 3, 1, -1, -1, -1, -1, -1, -1, -1],\n",
       "  5: [3, 2, 3, -1, -1, -1, -1, -1, -1, -1],\n",
       "  1: [4, -1, 4, -1, -1, -1, -1, -1, -1, -1]},\n",
       " 23: {1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  2: [1, -1, -1, -1, -1, 2, 1, 2, 1, 2]},\n",
       " 24: {3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  2: [1, 1, 2, 1, 2, 1, 1, 1, 1, 1],\n",
       "  1: [2, -1, 1, -1, 1, -1, -1, -1, -1, -1]}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_test = assignIDNumbers(f\"{output_dir}/{output_name}/frames\")\n",
    "ID_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dee6ba-b7f5-4074-9f7b-099a9b20ca91",
   "metadata": {},
   "source": [
    "## output frames with character labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ccc81f6a-2726-4ae4-8a60-e018a855f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bounding boxes\n",
    "lines = []\n",
    "boxes_fp = f\"{output_dir}/{output_name}/boxes.csv\"\n",
    "\n",
    "for i in range(len(results)):\n",
    "    lines.append(results[i].boxes)\n",
    "\n",
    "with open(boxes_fp, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write all lines to the CSV file\n",
    "    writer.writerows(lines)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5914262-6dc0-400e-b244-ffc1ddfd695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 566.,   93.,  756.,  685.],\n",
       "        [ 690.,   87.,  824.,  683.],\n",
       "        [ 506.,   35.,  664.,  679.],\n",
       "        [1166.,  289., 1274.,  385.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0e3555aa-67d9-4f8c-8479-3b101d256d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Params: \n",
    "\n",
    "frame_path: filepath of the frame (image file) \n",
    "person_ids: \n",
    "'''\n",
    "\n",
    "def draw_boxes_with_ids(frame_path, person_ids, positional_indexes, boxes):\n",
    "    frame = cv2.imread(f'{frame_path}.jpg')\n",
    "    \n",
    "    for person in person_ids:\n",
    "        x1, y1, x2, y2 = boxes.xyxy[positional_indexes[person]].numpy()\n",
    "\n",
    "        # Display person ID\n",
    "        cv2.putText(frame, str(person), (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 3)\n",
    "    \n",
    "    cv2.imwrite(f'{frame_path}_labels.jpg', frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d3f4fa36-4cc9-4158-b45d-6d6387dd792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_seq in sequences:\n",
    "    person_ids = IDs[i_seq].keys()\n",
    "    for i_frame in range(FRAMES_PER_SEQUENCE):\n",
    "        external_frame = (i_seq-1) * OVERLAP + i_frame\n",
    "        positional_indexes = {}\n",
    "        for person in person_ids:\n",
    "            positional_indexes[person] = IDs[i_seq][person][i_frame]\n",
    "        \n",
    "        frame_path = os.path.join(frames_fp, f\"frame_{external_frame+1:04d}\")\n",
    "        \n",
    "        draw_boxes_with_ids(frame_path, person_ids, positional_indexes, results[external_frame].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c2716ffa-7eef-4a27-9efd-5a2c3ec3cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save IDs\n",
    "import pickle\n",
    "IDs_fp = f\"{output_dir}/{output_name}/IDs.pkl\"\n",
    "\n",
    "with open(IDs_fp, 'wb') as file:\n",
    "    pickle.dump(IDs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f117b5e-3ac5-43c0-9fdb-ad1a5f9240ce",
   "metadata": {},
   "source": [
    "### If a person disappears during a sequence i.e., (-1) positional index, remove them from the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2b928e0d-c2be-490b-9dce-f792fbb33ce7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "18",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m internal_frame \u001b[38;5;241m=\u001b[39m external_frame \u001b[38;5;241m%\u001b[39m OVERLAP\n\u001b[1;32m     12\u001b[0m positional_indexes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 13\u001b[0m person_ids \u001b[38;5;241m=\u001b[39m \u001b[43mIDs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m person \u001b[38;5;129;01min\u001b[39;00m person_ids:\n\u001b[1;32m     15\u001b[0m     positional_indexes[person] \u001b[38;5;241m=\u001b[39m IDs[seq][person][internal_frame]\n",
      "\u001b[0;31mKeyError\u001b[0m: 18"
     ]
    }
   ],
   "source": [
    "for frame in sorted(os.listdir(frames_fp)): \n",
    "    frame_path = os.path.join(frames_fp,frame)\n",
    "    # true frame number (of vdeo)\n",
    "    external_frame = int(frame_path.split('_')[1][:4])\n",
    "    \n",
    "    # sequence index\n",
    "    seq = int(external_frame/OVERLAP) + 1\n",
    "    \n",
    "    # check if the sequence is actually kept (may have been deleted during preprocess)\n",
    "    \n",
    "    # frame within the sequence \n",
    "    internal_frame = external_frame % OVERLAP\n",
    "    \n",
    "    positional_indexes = {}\n",
    "    person_ids = IDs[seq].keys()\n",
    "    for person in person_ids:\n",
    "        positional_indexes[person] = IDs[seq][person][internal_frame]\n",
    "\n",
    "    frame_path = os.path.join(frames_fp, f\"frame_{external_frame+1:04d}\")\n",
    "\n",
    "    draw_boxes_with_ids(frame_path, person_ids, positional_indexes, results[external_frame].boxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
